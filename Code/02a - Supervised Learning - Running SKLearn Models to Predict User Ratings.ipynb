{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # Import Useful Packages\n",
    "- # Bring in key features / labels\n",
    "- # Determine features\n",
    "- # Create dictionary to hold model results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Useful Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring in key features / labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:20: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "##########################################################################################\n",
    "#################### Pulling in the Lookup Table for Movies #############################\n",
    "##########################################################################################\n",
    "lookup_table_movies = pd.read_pickle('lookup_table_movies.pickle')\n",
    "\n",
    "##########################################################################################\n",
    "#################### Pulling in the User Ratings #########################################\n",
    "##########################################################################################\n",
    "\n",
    "user_ratings = pd.read_pickle('user_ratings.pickle')\n",
    "\n",
    "# This contains all the movieIDs for which we have already compiled metadata info available (i.e. from hetrec)\n",
    "movies_with_metadata = lookup_table_movies[\"movieID\"].unique()  #10197 in length\n",
    "\n",
    "# This takes all the user ratings from the ml-latest download, and pairs it down to only those movies \n",
    "# for which we have metadata information.\n",
    "user_ratings_for_movies_with_metadata = user_ratings[user_ratings[\"movieID\"].isin(movies_with_metadata)] # 10196 in length\n",
    "\n",
    "# This creates special lists that will be used to bias our training set towards users with a lot of ratings.\n",
    "users_ordered_by_frequency_table = user_ratings_for_movies_with_metadata[[\"userID\",\"original_9\"]].groupby(\"userID\", as_index = False).count().sort('original_9', ascending=False)\n",
    "#users_ordered_by_frequency = list(users_ordered_by_frequency_table[\"userID\"])\n",
    "# These are the ID's of the 25000 most frequently rating users. \n",
    "#users_high_frequency_25000 = users_ordered_by_frequency[0:25000]  \n",
    "users_over20_reviews = users_ordered_by_frequency_table[users_ordered_by_frequency_table[\"original_9\"] > 20][\"userID\"]\n",
    "users_over30_reviews = users_ordered_by_frequency_table[users_ordered_by_frequency_table[\"original_9\"] > 30][\"userID\"]\n",
    "\n",
    "#user_ratings_high_frequency = user_ratings_for_movies_with_metadata[user_ratings_for_movies_with_metadata[\"userID\"].isin(users_w_most_ratings_25000)]\n",
    "# These are the ID's of the other are the less frequently rating users\n",
    "#users_low_frequency_remainder = users_ordered_by_frequency[25000:]\n",
    "#user_ratings_low_frequency = user_ratings_for_movies_with_metadata[user_ratings_for_movies_with_metadata[\"userID\"].isin(users_low_frequency_remainder)]\n",
    "\n",
    "##########################################################################################\n",
    "#################### Pulling in the Movie - X Feature Candidates #########################\n",
    "##########################################################################################\n",
    "imdb_and_rt_ratings_feature = pd.read_pickle('imdb_and_rt_ratings_feature.pickle') #<- ??Maybe I should consider dim. reducing these too?\n",
    "imdb_and_rt_ratings_feature_reduced = imdb_and_rt_ratings_feature[[\"movieID\",\"rtAllCriticsScore\",\"rtAudienceScore\"]]\n",
    "\n",
    "misc_movie_features = pd.read_pickle('misc_movie_features.pickle')\n",
    "\n",
    "#This is the full genre dummy feature... seems like perhaps I could test it whole since it's relatively small\n",
    "genre_feature_dummied = pd.read_pickle('genre_feature_dummied.pickle')\n",
    "\n",
    "#This is the svd shrunk features.\n",
    "directors_feature_dim_reduced = pd.read_pickle('directors_feature_dim_reduced.pickle')\n",
    "genre_feature_dim_reduced = pd.read_pickle('genre_feature_dim_reduced.pickle')\n",
    "tags_feature_dim_reduced= pd.read_pickle('tags_feature_dim_reduced.pickle')\n",
    "actors_feature_dim_reduced = pd.read_pickle('actors_feature_dim_reduced.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary to hold model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model_results_dict.pickle', 'rb') as handle:\n",
    "  model_results_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model_results_dict = {}\n",
    "\n",
    "# Sample Key: (label_type, feature_set, classifier_model, n_train_users, parameter_metadata_string ) = \n",
    "\n",
    "# Sample Stored Ouput:\n",
    "\n",
    "# Model_Details\n",
    "#  n_train_ratings\n",
    "#  n_test_ratings, \n",
    "#  n_test_users, \n",
    "# feature weights\n",
    "\n",
    "# Model_Performance\n",
    "#  confusion matrix\n",
    "#  accuracy, \n",
    "#  precision, \n",
    "#  recall, \n",
    "#  f_stat\n",
    "# \n",
    "\n",
    "##################### Explanation of Possible Values ##################### \n",
    "\n",
    "\n",
    "# label_type = how the \"y\" is coded in.\n",
    "# _______________________Example Values:_______________________\n",
    "# # binned_5 = ratings of 1,2,3,4,5\n",
    "# # original_9 = ratings of 0.5,1,1.5,2,2.5,3,3.5,4,4.5,5\n",
    "# # binary = ratings of <3 or <= 3\n",
    "# # binned_3 = ratings of <3, 3, >3\n",
    "\n",
    "\n",
    "# # n_train_users = number of unique users in the training set (note: these are biased towards selecting from the top 25000 most frequent users)\n",
    "# # n_test_users = number of unique users in the test set (note: these contain ALL of the users who not in the top 25k most frequent users and are biased towards selecting from the top 25000 most frequent users)\n",
    "\n",
    "## feature_set - what features grouping is this?\n",
    "# standard_features = year + genreDR + agg_ratingDR + director_DR + actorDR + tag_rating\n",
    "\n",
    "# classifier_model = the type of model that was used for classifcation. i.e.\n",
    "# _______________________Example Values:_______________________\n",
    "# multiclass_mle == multinomial maximum liklihood estimation\n",
    "# dtc = decision tree classifer\n",
    "# rfc = random forrest classifier\n",
    "# ada = adaboost classifier\n",
    "# svm = support vector machines\n",
    "# nn = neural networks\n",
    "\n",
    "# # n_train_ratings = number of observations in the training set\n",
    "# # n_test_ratings =  number of observations in the test set\n",
    "\n",
    "\n",
    "# parameter_metadata_string = a string composed of what values I gave the paramters if the classifier involved paramters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this, you should have:\n",
    "X_train, X_test, \n",
    "y_train_binary, y_test_binary\n",
    "y_train_original_9, y_test_original_9\n",
    "y_train_binned_3, y_train_binned_3\n",
    "y_test_binned_5, y_test_binned_5\n",
    "n_train_users -- len(x_train[\"users\"].unique())\n",
    "\n",
    "## (1) Create your \"everything\" matrix using the features you are interested in.\n",
    "##### [Delete some old variables to free up cache memory] i.e. list of features etc...\n",
    "## Choose # to have in your test set (from 25000 users) & split your data\n",
    "##### [Delete some old variables to free up cache memory] i.e. All_data]\n",
    "## Break out different \"y\" inputs depending on model\n",
    "##### [Delete some old variables to free up cache memory] i.e. list of frequency users, y train matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Create your \"everything_matrix\"\n",
    "#### Bumps Memory usage from 2/3gb -> 11/12gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge 1 Complete\n",
      "Merge 2 Complete\n",
      "Merge 3 Complete\n",
      "Merge 4 Complete\n",
      "Merge 5 Complete\n"
     ]
    }
   ],
   "source": [
    "# These steps may take a long time...\n",
    "All_data = pd.merge(user_ratings_for_movies_with_metadata,imdb_and_rt_ratings_feature_reduced, on = \"movieID\")\n",
    "print \"Merge 1 Complete\"\n",
    "# All_data = pd.merge(All_data,misc_movie_features, on = \"movieID\")\n",
    "print \"Merge 2 Complete\"\n",
    "All_data = pd.merge(All_data,directors_feature_dim_reduced, on = \"movieID\")\n",
    "print \"Merge 3 Complete\"\n",
    "All_data = pd.merge(All_data,genre_feature_dim_reduced, on = \"movieID\")\n",
    "print \"Merge 4 Complete\"\n",
    "#All_data = pd.merge(All_data,tags_feature_dim_reduced, on = \"movieID\")\n",
    "print \"Merge 5 Complete\"\n",
    "#All_data = pd.merge(All_data,actors_feature_dim_reduced, on = \"movieID\")\n",
    "#print \"Merge 6 Complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "All_data = All_data[All_data[\"userID\"].isin(users_over30_reviews)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Delete some old variables to free up cache memory] i.e. list of features etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      "actors_feature_dim_reduced\n",
      "directors_feature_dim_reduced\n",
      "genre_feature_dim_reduced\n",
      "genre_feature_dummied\n",
      "imdb_and_rt_ratings_feature\n",
      "imdb_and_rt_ratings_feature_reduced\n",
      "lookup_table_movies\n",
      "misc_movie_features\n",
      "movies_with_metadata\n",
      "tags_feature_dim_reduced\n",
      "user_ratings\n",
      "user_ratings_for_movies_with_metadata\n",
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Flushing output cache (6 entries)\n"
     ]
    }
   ],
   "source": [
    "#### Reduces Memory usage from 8.6gb -> 6\n",
    "this = sys.modules[__name__]\n",
    "list_of_vars_to_be_removed = [\"user_ratings\", \"movies_with_metadata\",\"user_ratings_for_movies_with_metadata\", \n",
    "                              \"imdb_and_rt_ratings_feature\",\"misc_movie_features\",  \"genre_feature_dummied\",\n",
    "                              \"directors_feature_dim_reduced\",  \"genre_feature_dim_reduced\",\"tags_feature_dim_reduced\",\n",
    "                              \"actors_feature_dim_reduced\", \"lookup_table_movies\",\"user_ratings_totals\",\n",
    "                              \"users_ordered_by_frequency\",\"users_w_most_ratings_25000\",\"user_ratings_totals_top75000\",\n",
    "                              \"user_ratings_for_movies_with_metadata_ratings_count\",\"top25000\",\"y_train\",\n",
    "                              \"Y_not_top25000\", \"user_ratings_user_ratings_for_movies_with_metadata_small\",\"X_train\",\n",
    "                             \"imdb_and_rt_ratings_feature_reduced\"]\n",
    "\n",
    "# [v for v in globals().keys() if not v.startswith('_')] # <-- Seems to be the same as that\n",
    "#for i in vars().keys():  # <-- Seems to be the same as that\n",
    "for i in dir():    \n",
    "    if i[0] != \"_\":\n",
    "        if i in list_of_vars_to_be_removed:\n",
    "            print i\n",
    "            delattr(this,str(i))\n",
    "\n",
    "%reset out        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some minor data cleanup...dropping NA's before splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "All_data = All_data.dropna()    #Drops all rows with NA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19295303, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>binned_5</th>\n",
       "      <th>binned_3</th>\n",
       "      <th>binary</th>\n",
       "      <th>original_9</th>\n",
       "      <th>rtAllCriticsScore</th>\n",
       "      <th>rtAudienceScore</th>\n",
       "      <th>director_nmf_vector_0</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_nmf_vector_0</th>\n",
       "      <th>genre_nmf_vector_1</th>\n",
       "      <th>genre_nmf_vector_2</th>\n",
       "      <th>genre_nmf_vector_3</th>\n",
       "      <th>genre_nmf_vector_4</th>\n",
       "      <th>genre_nmf_vector_5</th>\n",
       "      <th>genre_nmf_vector_6</th>\n",
       "      <th>genre_nmf_vector_7</th>\n",
       "      <th>genre_nmf_vector_8</th>\n",
       "      <th>genre_nmf_vector_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>39.236357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073128</td>\n",
       "      <td>4.100759</td>\n",
       "      <td>1.114735</td>\n",
       "      <td>0.566696</td>\n",
       "      <td>0.733227</td>\n",
       "      <td>4.401808</td>\n",
       "      <td>3.831007</td>\n",
       "      <td>1.563178</td>\n",
       "      <td>0.231911</td>\n",
       "      <td>4.135643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>169</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>39.236357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073128</td>\n",
       "      <td>4.100759</td>\n",
       "      <td>1.114735</td>\n",
       "      <td>0.566696</td>\n",
       "      <td>0.733227</td>\n",
       "      <td>4.401808</td>\n",
       "      <td>3.831007</td>\n",
       "      <td>1.563178</td>\n",
       "      <td>0.231911</td>\n",
       "      <td>4.135643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>39.236357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073128</td>\n",
       "      <td>4.100759</td>\n",
       "      <td>1.114735</td>\n",
       "      <td>0.566696</td>\n",
       "      <td>0.733227</td>\n",
       "      <td>4.401808</td>\n",
       "      <td>3.831007</td>\n",
       "      <td>1.563178</td>\n",
       "      <td>0.231911</td>\n",
       "      <td>4.135643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>39.236357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073128</td>\n",
       "      <td>4.100759</td>\n",
       "      <td>1.114735</td>\n",
       "      <td>0.566696</td>\n",
       "      <td>0.733227</td>\n",
       "      <td>4.401808</td>\n",
       "      <td>3.831007</td>\n",
       "      <td>1.563178</td>\n",
       "      <td>0.231911</td>\n",
       "      <td>4.135643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>178</td>\n",
       "      <td>169</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>39.236357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073128</td>\n",
       "      <td>4.100759</td>\n",
       "      <td>1.114735</td>\n",
       "      <td>0.566696</td>\n",
       "      <td>0.733227</td>\n",
       "      <td>4.401808</td>\n",
       "      <td>3.831007</td>\n",
       "      <td>1.563178</td>\n",
       "      <td>0.231911</td>\n",
       "      <td>4.135643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating  binned_5  binned_3  binary  original_9  \\\n",
       "1      13      169     1.0       1.0       1.0     0.0         2.0   \n",
       "2      14      169     3.0       3.0       3.0     1.0         6.0   \n",
       "3      17      169     1.0       1.0       1.0     0.0         2.0   \n",
       "4      68      169     1.0       1.0       1.0     0.0         2.0   \n",
       "5     178      169     2.5       3.0       1.0     0.0         5.0   \n",
       "\n",
       "   rtAllCriticsScore  rtAudienceScore  director_nmf_vector_0  \\\n",
       "1               25.0             53.0              39.236357   \n",
       "2               25.0             53.0              39.236357   \n",
       "3               25.0             53.0              39.236357   \n",
       "4               25.0             53.0              39.236357   \n",
       "5               25.0             53.0              39.236357   \n",
       "\n",
       "          ...          genre_nmf_vector_0  genre_nmf_vector_1  \\\n",
       "1         ...                    0.073128            4.100759   \n",
       "2         ...                    0.073128            4.100759   \n",
       "3         ...                    0.073128            4.100759   \n",
       "4         ...                    0.073128            4.100759   \n",
       "5         ...                    0.073128            4.100759   \n",
       "\n",
       "   genre_nmf_vector_2  genre_nmf_vector_3  genre_nmf_vector_4  \\\n",
       "1            1.114735            0.566696            0.733227   \n",
       "2            1.114735            0.566696            0.733227   \n",
       "3            1.114735            0.566696            0.733227   \n",
       "4            1.114735            0.566696            0.733227   \n",
       "5            1.114735            0.566696            0.733227   \n",
       "\n",
       "   genre_nmf_vector_5  genre_nmf_vector_6  genre_nmf_vector_7  \\\n",
       "1            4.401808            3.831007            1.563178   \n",
       "2            4.401808            3.831007            1.563178   \n",
       "3            4.401808            3.831007            1.563178   \n",
       "4            4.401808            3.831007            1.563178   \n",
       "5            4.401808            3.831007            1.563178   \n",
       "\n",
       "   genre_nmf_vector_8  genre_nmf_vector_9  \n",
       "1            0.231911            4.135643  \n",
       "2            0.231911            4.135643  \n",
       "3            0.231911            4.135643  \n",
       "4            0.231911            4.135643  \n",
       "5            0.231911            4.135643  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print All_data.shape\n",
    "All_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19295303, 4)\n"
     ]
    }
   ],
   "source": [
    "Y = All_data[[\"binned_5\",\"binned_3\",\"binary\",\"original_9\"]]\n",
    "print Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## I'm not sure why, but this takes a lot of time to load, so I'm going to try it my old way...\n",
    "X = All_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>binned_5</th>\n",
       "      <th>binned_3</th>\n",
       "      <th>binary</th>\n",
       "      <th>original_9</th>\n",
       "      <th>rtAllCriticsScore</th>\n",
       "      <th>rtAudienceScore</th>\n",
       "      <th>director_nmf_vector_0</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_nmf_vector_0</th>\n",
       "      <th>genre_nmf_vector_1</th>\n",
       "      <th>genre_nmf_vector_2</th>\n",
       "      <th>genre_nmf_vector_3</th>\n",
       "      <th>genre_nmf_vector_4</th>\n",
       "      <th>genre_nmf_vector_5</th>\n",
       "      <th>genre_nmf_vector_6</th>\n",
       "      <th>genre_nmf_vector_7</th>\n",
       "      <th>genre_nmf_vector_8</th>\n",
       "      <th>genre_nmf_vector_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>39.236357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073128</td>\n",
       "      <td>4.100759</td>\n",
       "      <td>1.114735</td>\n",
       "      <td>0.566696</td>\n",
       "      <td>0.733227</td>\n",
       "      <td>4.401808</td>\n",
       "      <td>3.831007</td>\n",
       "      <td>1.563178</td>\n",
       "      <td>0.231911</td>\n",
       "      <td>4.135643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>169</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>39.236357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073128</td>\n",
       "      <td>4.100759</td>\n",
       "      <td>1.114735</td>\n",
       "      <td>0.566696</td>\n",
       "      <td>0.733227</td>\n",
       "      <td>4.401808</td>\n",
       "      <td>3.831007</td>\n",
       "      <td>1.563178</td>\n",
       "      <td>0.231911</td>\n",
       "      <td>4.135643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>39.236357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073128</td>\n",
       "      <td>4.100759</td>\n",
       "      <td>1.114735</td>\n",
       "      <td>0.566696</td>\n",
       "      <td>0.733227</td>\n",
       "      <td>4.401808</td>\n",
       "      <td>3.831007</td>\n",
       "      <td>1.563178</td>\n",
       "      <td>0.231911</td>\n",
       "      <td>4.135643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68</td>\n",
       "      <td>169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>39.236357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073128</td>\n",
       "      <td>4.100759</td>\n",
       "      <td>1.114735</td>\n",
       "      <td>0.566696</td>\n",
       "      <td>0.733227</td>\n",
       "      <td>4.401808</td>\n",
       "      <td>3.831007</td>\n",
       "      <td>1.563178</td>\n",
       "      <td>0.231911</td>\n",
       "      <td>4.135643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>178</td>\n",
       "      <td>169</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>39.236357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073128</td>\n",
       "      <td>4.100759</td>\n",
       "      <td>1.114735</td>\n",
       "      <td>0.566696</td>\n",
       "      <td>0.733227</td>\n",
       "      <td>4.401808</td>\n",
       "      <td>3.831007</td>\n",
       "      <td>1.563178</td>\n",
       "      <td>0.231911</td>\n",
       "      <td>4.135643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating  binned_5  binned_3  binary  original_9  \\\n",
       "1      13      169     1.0       1.0       1.0     0.0         2.0   \n",
       "2      14      169     3.0       3.0       3.0     1.0         6.0   \n",
       "3      17      169     1.0       1.0       1.0     0.0         2.0   \n",
       "4      68      169     1.0       1.0       1.0     0.0         2.0   \n",
       "5     178      169     2.5       3.0       1.0     0.0         5.0   \n",
       "\n",
       "   rtAllCriticsScore  rtAudienceScore  director_nmf_vector_0  \\\n",
       "1               25.0             53.0              39.236357   \n",
       "2               25.0             53.0              39.236357   \n",
       "3               25.0             53.0              39.236357   \n",
       "4               25.0             53.0              39.236357   \n",
       "5               25.0             53.0              39.236357   \n",
       "\n",
       "          ...          genre_nmf_vector_0  genre_nmf_vector_1  \\\n",
       "1         ...                    0.073128            4.100759   \n",
       "2         ...                    0.073128            4.100759   \n",
       "3         ...                    0.073128            4.100759   \n",
       "4         ...                    0.073128            4.100759   \n",
       "5         ...                    0.073128            4.100759   \n",
       "\n",
       "   genre_nmf_vector_2  genre_nmf_vector_3  genre_nmf_vector_4  \\\n",
       "1            1.114735            0.566696            0.733227   \n",
       "2            1.114735            0.566696            0.733227   \n",
       "3            1.114735            0.566696            0.733227   \n",
       "4            1.114735            0.566696            0.733227   \n",
       "5            1.114735            0.566696            0.733227   \n",
       "\n",
       "   genre_nmf_vector_5  genre_nmf_vector_6  genre_nmf_vector_7  \\\n",
       "1            4.401808            3.831007            1.563178   \n",
       "2            4.401808            3.831007            1.563178   \n",
       "3            4.401808            3.831007            1.563178   \n",
       "4            4.401808            3.831007            1.563178   \n",
       "5            4.401808            3.831007            1.563178   \n",
       "\n",
       "   genre_nmf_vector_8  genre_nmf_vector_9  \n",
       "1            0.231911            4.135643  \n",
       "2            0.231911            4.135643  \n",
       "3            0.231911            4.135643  \n",
       "4            0.231911            4.135643  \n",
       "5            0.231911            4.135643  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All_data\n",
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Flushing output cache (3 entries)\n"
     ]
    }
   ],
   "source": [
    "this = sys.modules[__name__]\n",
    "list_of_vars_to_be_removed = [\"All_data\"]\n",
    "\n",
    "for i in dir():    \n",
    "    if i[0] != \"_\":\n",
    "        if i in list_of_vars_to_be_removed:\n",
    "            print i\n",
    "            delattr(this,str(i))\n",
    "\n",
    "%reset out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.drop([\"binned_5\",\"binned_3\",\"binary\",\"original_9\",\"rating\"],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Splitting your data old / wrong way which chose only those users with a lot of ratings...\n",
    "\n",
    "# n_train_users = 10\n",
    "# n_test_users = len(All_data[\"userID\"].unique()) - n_train_users\n",
    "# lucky_training_set_users = np.random.choice(users_high_frequency_25000, n_train_users, replace = False )\n",
    "\n",
    "# X_train = All_data[All_data[\"userID\"].isin(lucky_training_set_users)].drop(['movieID', \"original_9\",\"binned_5\",\"binned_3\",\"binary\"], axis=1)\n",
    "# Y_train = All_data[[\"original_9\",\"binned_5\",\"binned_3\",\"binary\"]][All_data[\"userID\"].isin(lucky_training_set_users)]\n",
    "\n",
    "# X_test = All_data[-All_data[\"userID\"].isin(lucky_training_set_users)].drop(['movieID', \"original_9\",\"binned_5\",\"binned_3\",\"binary\"], axis=1)\n",
    "# Y_test = All_data[[\"original_9\",\"binned_5\",\"binned_3\",\"binary\"]][-All_data[\"userID\"].isin(lucky_training_set_users)]\n",
    "\n",
    "# n_train_ratings = X_train.shape[0]\n",
    "# n_test_ratings = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train_ratings = X_train.shape[0]\n",
    "n_test_ratings = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15436242\n",
      "3859061\n"
     ]
    }
   ],
   "source": [
    "print n_train_ratings\n",
    "print n_test_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [Delete some old variables to free up cache memory] i.e. All_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "Y\n",
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Flushing output cache (0 entries)\n"
     ]
    }
   ],
   "source": [
    "# Bumps data demands from 17gb to 12gb\n",
    "\n",
    "this = sys.modules[__name__]\n",
    "list_of_vars_to_be_removed = [\"X\",\"Y\"]\n",
    "\n",
    "for i in dir():    \n",
    "    if i[0] != \"_\":\n",
    "        if i in list_of_vars_to_be_removed:\n",
    "            print i\n",
    "            delattr(this,str(i))\n",
    "\n",
    "%reset out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Subdivide Y matrix into individual series\n",
    "??? Could i have just run the models with a matrix set of y's??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train_original_9 = y_train[\"original_9\"]\n",
    "y_train_binned_5 = y_train[\"binned_5\"]\n",
    "y_train_binned_3 = y_train[\"binned_3\"]\n",
    "y_train_binary = y_train[\"binary\"]\n",
    "\n",
    "y_test_original_9 = y_test[\"original_9\"]\n",
    "y_test_binned_5 = y_test[\"binned_5\"]\n",
    "y_test_binned_3 = y_test[\"binned_3\"]\n",
    "y_test_binary = y_test[\"binary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15436242,)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3859061,)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 5\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test\n",
      "y_train\n",
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "Flushing output cache (3 entries)\n"
     ]
    }
   ],
   "source": [
    "this = sys.modules[__name__]\n",
    "list_of_vars_to_be_removed = [\"y_train\",\"y_test\"]\n",
    "\n",
    "for i in dir():    \n",
    "    if i[0] != \"_\":\n",
    "        if i in list_of_vars_to_be_removed:\n",
    "            print i\n",
    "            delattr(this,str(i))\n",
    "\n",
    "%reset out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some prepwork before running models...\n",
    "### Importing Packages...\n",
    "### Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model_object(model_type,model_params):\n",
    "    if model_type == \"dtc\":\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        return DecisionTreeClassifier()\n",
    "    elif model_type == \"MNB\":\n",
    "        from sklearn.naive_bayes import MultinomialNB\n",
    "        return MultinomialNB()\n",
    "    elif model_type == \"RFC\":\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        return RandomForestClassifier(n_jobs= -1)\n",
    "    elif model_type == \"Ada\":\n",
    "        from sklearn.ensemble import AdaBoostClassifier\n",
    "        return AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_score(y_true,y_pred, label_type, feature_weights):\n",
    "    model_confusion_matrix = confusion_matrix(y_true, y_pred)\n",
    "    model_accuracy_score = accuracy_score(y_true, y_pred)\n",
    "    model_f1_score = f1_score(y_true, y_pred, average= \"micro\")\n",
    "    model_precision = precision_score(y_true, y_pred, average= \"micro\")\n",
    "    model_recall = recall_score(y_true, y_pred, average= \"micro\")\n",
    "    \n",
    "    # Generate Key\n",
    "    # Sample Key: (label_type, feature_set, classifier_model, n_train_users )\n",
    "    model_key = (label_type, feature_set, model_type, n_train_users,model_params)\n",
    "    print model_key\n",
    "    \n",
    "    # Generate Value\n",
    "    model_values = (n_train_ratings,n_test_ratings, n_test_users, feature_weights, \n",
    "                model_confusion_matrix, model_accuracy_score, model_precision,\n",
    "               model_recall, model_f1_score)\n",
    "    print model_values\n",
    "    \n",
    "    model_results_dict[model_key] = model_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model_save_results(feature_set,model_type, n_train_users, model_params):\n",
    "    model_object = create_model_object(model_type,model_params)\n",
    "    \n",
    "    # Train model -> Predict Y-test -> Generate scores & save to dictionary\n",
    "    model_object.fit(X_train,y_train_binary)\n",
    "    print \"y_train_binary - (1) Finished fitting model\"\n",
    "    try:\n",
    "        feature_weights = zip(X_train.columns, model_object.feature_importances_)\n",
    "    except:\n",
    "        feature_weights = \"\"\n",
    "    print \"feature weights saved\"\n",
    "    y_pred = model_object.predict(X_test)\n",
    "    print \"y_train_binary - (2) Finished predicting y_pred (test set)\"\n",
    "    model_score(y_test_binary,y_pred,\"binary\", feature_weights)\n",
    "    print \"y_train_binary - (3) Finished generating scores\"\n",
    "    \n",
    "    # Train model -> Predict Y-test -> Generate scores & save to dictionary\n",
    "    model_object.fit(X_train,y_train_binned_5)\n",
    "    print \"y_train_binned_5 - (1) Finished fitting model\"\n",
    "    try:\n",
    "        feature_weights = zip(X_train.columns, model_object.feature_importances_)\n",
    "    except:\n",
    "        feature_weights = \"\"\n",
    "    print \"feature weights saved\"\n",
    "    y_pred = model_object.predict(X_test)\n",
    "    print \"y_train_binned_5 - (2) Finished predicting y_pred (test set)\"\n",
    "    model_score(y_test_binned_5,y_pred, \"binned_5\",feature_weights)\n",
    "    print \"y_train_binned_5 - (3) Finished generating scores\"\n",
    "\n",
    "    # Train model -> Predict Y-test -> Generate scores & save to dictionary\n",
    "    model_object.fit(X_train,y_train_binned_3)\n",
    "    print \"y_train_binned_3 - (1) Finished fitting model\"\n",
    "    try:\n",
    "        feature_weights = zip(X_train.columns, model_object.feature_importances_)\n",
    "    except:\n",
    "        feature_weights = \"\"\n",
    "    print \"feature weights saved\"\n",
    "    y_pred = model_object.predict(X_test)\n",
    "    print \"y_train_binned_3 - (2) Finished predicting y_pred (test set)\"\n",
    "    model_score(y_test_binned_3,y_pred, \"binned_3\",feature_weights)\n",
    "    print \"y_train_binned_3 - (3) Finished generating scores\"\n",
    "    \n",
    "    # Train model -> Predict Y-test -> Generate scores & save to dictionary\n",
    "    model_object.fit(X_train,y_train_original_9)\n",
    "    print \"y_train_original_9 - (1) Finished fitting model\"\n",
    "    try:\n",
    "        feature_weights = zip(X_train.columns, model_object.feature_importances_)\n",
    "    except:\n",
    "        feature_weights = \"\"\n",
    "    print \"feature weights saved\"\n",
    "    y_pred = model_object.predict(X_test)\n",
    "    print \"y_train_original_9 - (2) Finished predicting y_pred (test set)\"\n",
    "    model_score(y_test_original_9,y_pred, \"original_9\",feature_weights)\n",
    "    print \"y_train_original_9 - (3) Finished generating scores\"\n",
    "    \n",
    "    print\n",
    "    print \"whooray, you're done with this set\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, let's run some models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ! I'm not sure what happened here...may need to investigate..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train_users = len(X_train[\"userID\"].unique())\n",
    "n_test_users = len(X_test[\"userID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train_binary - (1) Finished fitting model\n",
      "feature weights saved\n",
      "y_train_binary - (2) Finished predicting y_pred (test set)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:931: DeprecationWarning: From version 0.18, binary input will not be handled specially when using averaged precision/recall/F-score. Please use average='binary' to report only the positive class performance.\n",
      "  'positive class performance.', DeprecationWarning)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:931: DeprecationWarning: From version 0.18, binary input will not be handled specially when using averaged precision/recall/F-score. Please use average='binary' to report only the positive class performance.\n",
      "  'positive class performance.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "('binary', 'UsersOver30_UserRatings_Genre_Director', 'MNB', 116709, '')\n",
      "(15436242, 3859061, 116701, '', array([[ 178820,  503083],\n",
      "       [ 738944, 2438214]]), 0.67815305329457087, 0.82895878926881572, 0.76741981355664401, 0.79700316501469726)\n",
      "y_train_binary - (3) Finished generating scores\n",
      "y_train_binned_5 - (1) Finished fitting model\n",
      "feature weights saved\n",
      "y_train_binned_5 - (2) Finished predicting y_pred (test set)\n",
      "('binned_5', 'UsersOver30_UserRatings_Genre_Director', 'MNB', 116709, '')\n",
      "(15436242, 3859061, 116701, '', array([[   1578,    2278,  124326,   45448,    4642],\n",
      "       [   2435,    3373,  235366,   81588,    9279],\n",
      "       [   5763,    7485,  719756,  232059,   29650],\n",
      "       [   8321,   10048, 1021646,  407815,   50229],\n",
      "       [   3490,    4052,  606178,  211798,   30458]]), 0.30136346639765477, 0.30136346639765477, 0.30136346639765477, 0.30136346639765477)\n",
      "y_train_binned_5 - (3) Finished generating scores\n",
      "y_train_binned_3 - (1) Finished fitting model\n",
      "feature weights saved\n",
      "y_train_binned_3 - (2) Finished predicting y_pred (test set)\n",
      "('binned_3', 'UsersOver30_UserRatings_Genre_Director', 'MNB', 116709, '')\n",
      "(15436242, 3859061, 116701, '', array([[  14662,  472435,  194806],\n",
      "       [  10151,  624482,  188490],\n",
      "       [  30186, 1651558,  672291]]), 0.33983266913894339, 0.33983266913894339, 0.33983266913894339, 0.33983266913894339)\n",
      "y_train_binned_3 - (3) Finished generating scores\n",
      "y_train_original_9 - (1) Finished fitting model\n",
      "feature weights saved\n",
      "y_train_original_9 - (2) Finished predicting y_pred (test set)\n",
      "('original_9', 'UsersOver30_UserRatings_Genre_Director', 'MNB', 116709, '')\n",
      "(15436242, 3859061, 116701, '', array([[   196,  19214,   1407,   1053,    139,    415,  13063,   3108,\n",
      "          1487,   7384],\n",
      "       [   303,  67848,   2698,   1745,    246,   1034,  18927,   7078,\n",
      "          4321,  26606],\n",
      "       [   185,  22745,   1613,   1097,    139,    447,  13930,   3517,\n",
      "          1685,   8937],\n",
      "       [   502, 135454,   5654,   3574,    426,   2273,  42626,  15426,\n",
      "         10034,  61777],\n",
      "       [   456,  67902,   4726,   3368,    409,   1635,  44520,  11144,\n",
      "          5994,  31436],\n",
      "       [  1069, 377431,  13380,   8194,    932,   5896, 116693,  40980,\n",
      "         31822, 226726],\n",
      "       [   949, 150972,  10831,   7287,    803,   4339, 114444,  28450,\n",
      "         17746,  91615],\n",
      "       [  1271, 428826,  17801,  10392,   1100,   8704, 174658,  58697,\n",
      "         48396, 320778],\n",
      "       [   538,  96176,   6730,   4287,    400,   2808,  76278,  19046,\n",
      "         13740,  75966],\n",
      "       [   471, 218514,   6803,   3689,    369,   3728,  69740,  27355,\n",
      "         27023, 202315]]), 0.12146270815620691, 0.12146270815620691, 0.12146270815620691, 0.12146270815620691)\n",
      "y_train_original_9 - (3) Finished generating scores\n",
      "\n",
      "whooray, you're done with this set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:931: DeprecationWarning: From version 0.18, binary input will not be handled specially when using averaged precision/recall/F-score. Please use average='binary' to report only the positive class performance.\n",
      "  'positive class performance.', DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Some prelimary variables\n",
    "feature_set = \"UsersOver30_UserRatings_Genre_Director\"\n",
    "model_type = \"MNB\"\n",
    "model_params = \"\"\n",
    "\n",
    "run_model_save_results(feature_set,model_type,n_train_users,model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 5\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-4baf2ed83876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrun_model_save_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_train_users\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-152-1bbffe791b7f>\u001b[0m in \u001b[0;36mrun_model_save_results\u001b[0;34m(feature_set, model_type, n_train_users, model_params)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Train model -> Predict Y-test -> Generate scores & save to dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"y_train_binary - (1) Finished fitting model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 273\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    664\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Some prelimary variables\n",
    "feature_set = \"UsersOver30_UserRatings_Genre_Director\"\n",
    "model_type = \"RFC\"\n",
    "model_params = \"\"\n",
    "\n",
    "run_model_save_results(feature_set,model_type,n_train_users,model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some prelimary variables\n",
    "feature_set = \"UsersOver30_UserRatings_Genre_Director\"\n",
    "model_type = \"Ada\"\n",
    "model_params = \"\"\n",
    "\n",
    "run_model_save_results(feature_set,model_type,n_train_users,model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_results_dict[model_key] = model_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('binned_3', 'All_main', 'MNB', 6664, ''),\n",
       " ('original_9', 'All_main', 'RFC', 6664, ''),\n",
       " ('binned_5', 'All_main', 'dtc', 10, ''),\n",
       " ('binary', 'All_main', 'MNB', 6664, ''),\n",
       " ('binned_3', 'All_main', 'RFC', 6664, ''),\n",
       " ('binary', 'All_main', 'Ada', 6664, ''),\n",
       " ('binned_3', 'All_main', 'dtc', 10, ''),\n",
       " ('binned_3', 'All_main', 'Ada', 6664, ''),\n",
       " ('binned_5', 'All_main', 'Ada', 6664, ''),\n",
       " ('original_9', 'All_main', 'MNB', 6664, ''),\n",
       " ('binned_5', 'All_main', 'MNB', 6664, ''),\n",
       " ('binary', 'All_main', 'dtc', 10, ''),\n",
       " ('binned_5', 'All_main', 'RFC', 6664, ''),\n",
       " ('binary', 'All_main', 'RFC', 6664, ''),\n",
       " ('original_9', 'All_main', 'Ada', 6664, '')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in [y_label_type, feature_set,model_type, user_count, n_train_ratings,n_test_users,model_accuracy_score, model_precision,model_recall,model_f1_score]:\n",
    "    i = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_label_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k,v in model_results_dict.iteritems():\n",
    "    y_label_type = k[0]\n",
    "    feature_set = k[1]\n",
    "    model_type = k[2]\n",
    "    user_count = k[3]\n",
    "    \n",
    "    n_train_ratings = v[0]\n",
    "    n_test_users = v[2]\n",
    "    model_accuracy_score = v[5]\n",
    "    model_precision= v[6]\n",
    "    model_recall= v[7]\n",
    "    model_f1_score= v[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_results_df = pd.DataFrame([y_label_type, feature_set,model_type, user_count, n_train_ratings,n_test_users,model_accuracy_score, model_precision,model_recall,model_f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All_main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.277667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.277667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.277667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.277667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0  original_9\n",
       "1    All_main\n",
       "2         Ada\n",
       "3        6664\n",
       "4        7000\n",
       "5        2942\n",
       "6    0.277667\n",
       "7    0.277667\n",
       "8    0.277667\n",
       "9    0.277667"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('model_results_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(model_results_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sorted([v for v in globals().keys() if not v.startswith('_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# this = sys.modules[__name__]\n",
    "# list_of_vars_to_be_removed = [\"y_pred\"]\n",
    "\n",
    "# # [v for v in globals().keys() if not v.startswith('_')] # <-- Seems to be the same as that\n",
    "# #for i in vars().keys():  # <-- Seems to be the same as that\n",
    "# for i in dir():    \n",
    "#     if i[0] != \"_\":\n",
    "#         if i in list_of_vars_to_be_removed:\n",
    "#             print i\n",
    "#             delattr(this,str(i))\n",
    "\n",
    "# %reset out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
